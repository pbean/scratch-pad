name: Performance Testing and Monitoring

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run performance tests daily at 4 AM UTC
    - cron: '0 4 * * *'
  workflow_dispatch:
    inputs:
      platforms:
        description: 'Platforms to test (JSON array)'
        required: false
        default: '["ubuntu-latest"]'  # Simplified to ubuntu-latest only
        type: string
      performance-monitoring:
        description: 'Enable detailed performance monitoring'
        required: false
        default: false  # Disabled by default for speed
        type: boolean
      test-coverage:
        description: 'Generate test coverage reports'
        required: false
        default: false
        type: boolean

env:
  CARGO_TERM_COLOR: always

jobs:
  performance-test:
    name: Performance Test Suite
    runs-on: ubuntu-latest  # Fixed to ubuntu-latest only for stability
    timeout-minutes: 10  # OPTIMIZED: Reduced from 15 to 10 minutes
    # Make performance tests non-blocking for PRs
    continue-on-error: ${{ github.event_name == 'pull_request' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Setup Node.js and PNPM
        uses: ./.github/actions/setup-node-pnpm

      - name: Setup Rust toolchain
        uses: ./.github/actions/setup-rust

      - name: Install Linux dependencies
        uses: ./.github/actions/install-linux-deps

      - name: Run performance tests (optimized)
        shell: bash
        run: |
          echo "Running performance tests with optimized CI configuration"
          export NODE_OPTIONS="--max-old-space-size=2048"  # Reduced memory
          
          # OPTIMIZED: Run frontend tests with explicit performance tracking disabled
          export PERFORMANCE_TRACKING_ENABLED=false
          export DISABLE_PERFORMANCE_TRACKING=true
          export VITEST_PERFORMANCE_DISABLED=true
          
          # Run frontend tests with optimized CI config
          pnpm test --run --config vitest.ci.config.ts --reporter=basic || {
            echo "Frontend tests failed, continuing with backend tests"
            exit_code=1
          }
          
          # Run backend tests with optimized settings
          cd src-tauri && RUST_TEST_THREADS=2 cargo test --lib --release --quiet || {
            echo "Backend tests failed"
            exit_code=1
          }
          
          # Exit with error code if any tests failed
          exit ${exit_code:-0}

      - name: Build application (minimal)
        shell: bash
        run: |
          # OPTIMIZED: Minimal build to verify compilation only
          echo "Running minimal build verification"
          
          # Frontend build with optimizations
          pnpm build --mode production || {
            echo "Frontend build failed"
            exit 1
          }
          
          # Backend build check only (skip full build)
          cd src-tauri && cargo check --release || {
            echo "Backend check failed" 
            exit 1
          }

  performance-analysis:
    name: Performance Analysis
    runs-on: ubuntu-latest
    needs: performance-test
    if: always() && (github.event.inputs.performance-monitoring == 'true' || github.event_name == 'schedule')
    timeout-minutes: 5  # OPTIMIZED: Added timeout for analysis job
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Create performance report
        shell: bash
        run: |
          mkdir -p performance-results
          
          # OPTIMIZED: Simplified performance report
          cat > performance-results/report.md << 'EOF'
          # Performance Test Report
          
          **Date**: $(date -Iseconds)
          **Commit**: ${{ github.sha }}
          **Workflow**: ${{ github.workflow }}
          **Status**: ${{ needs.performance-test.result }}
          
          ## Summary
          
          - Frontend tests: ${{ needs.performance-test.result == 'success' && '✅ Completed' || '❌ Failed' }}
          - Backend tests: ${{ needs.performance-test.result == 'success' && '✅ Completed' || '❌ Failed' }}
          - Application build: ${{ needs.performance-test.result == 'success' && '✅ Completed' || '❌ Failed' }}
          
          ## Configuration (Optimized for CI)
          
          - Platform: ubuntu-latest
          - Node.js: 20 (2048MB memory limit)
          - Rust: stable (2 test threads)
          - Performance tracking: Disabled for speed
          - Test timeout: 10 minutes
          - Build verification: Minimal mode
          
          ## Performance Optimizations Applied
          
          - Disabled performance tracking overhead
          - Reduced memory allocation (2048MB)
          - Minimal build verification
          - Optimized test timeouts
          - Basic test reporting for speed
          
          EOF
          
          echo "Performance analysis completed"

      - name: Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report-optimized
          path: performance-results/
          retention-days: 3  # OPTIMIZED: Reduced retention